{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**E-Commerce Customer Churn Analysis and Segmentation**\n",
        "**Author:** Hasan Raja Khan - Data Analyst\n",
        "\n",
        "**Purpose:**\n",
        "\n",
        "*   This script performs comprehensive analysis of e-commerce customer data to predict churn, segment customers using RFM (Recency, Frequency, Monetary) analysis and recommend targeted treatments.\n",
        "\n",
        "*   It includes exploratory data analysis, machine learning modeling, clustering and ROI calculations.\n",
        "\n"
      ],
      "metadata": {
        "id": "Hqij4XqpPnJA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raCpkkzHQRh9"
      },
      "source": [
        "####**Importing Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMhHwVdiQ8bE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score, classification_report, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "import plotly.express as px\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axpi2LRHUCk6"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTeuByA_USaT"
      },
      "source": [
        "####**Loading Dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ6ew0EjU7cC"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"/content/E Commerce Dataset.xlsx\", sheet_name=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX064IGoXG9b"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wc6shAAOgU-"
      },
      "source": [
        "####**Exploratory Data Analysis (EDA)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGQLHV3Se3_o"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrFELp1Xfz1O"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPvgAma4de8x"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjCfmqsieOsn"
      },
      "outputs": [],
      "source": [
        "# Visualizes missing values to identify gaps\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KhRI0Tdfj-j"
      },
      "outputs": [],
      "source": [
        "# Numerical Features Distribution\n",
        "# Plotting boxplots for numerical columns to check outliers\n",
        "\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(numerical_cols, 1):\n",
        "    plt.subplot(4, 5, i)\n",
        "    sns.boxplot(y=df[col])\n",
        "    plt.title(col)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2dwMSN5gcZv"
      },
      "outputs": [],
      "source": [
        "# Categorical Features vs Churn\n",
        "# Plotting bar charts for categorical features vs churn\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.countplot(x=col, hue='Churn', data=df)\n",
        "    plt.title(f'{col} vs Churn')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi2XyHUJg6Ri"
      },
      "outputs": [],
      "source": [
        "# Correlation Matrix\n",
        "# Shows correlations between numerical features\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df[numerical_cols].corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Churn has a negative correlation with **Tenure** (-0.35) and **CashbackAmount** (-0.15) → longer-tenure and higher-cashback users are less likely to churn.\n",
        "\n",
        "**OrderCount** and **CouponUsed** are highly correlated (0.75) which means frequent buyers tend to use more coupons.\n",
        "\n",
        "Most features show low correlation with each other, suggesting minimal multicollinearity."
      ],
      "metadata": {
        "id": "WO3hPd-VCSbs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg9t8AUzjln7"
      },
      "outputs": [],
      "source": [
        "# Churn Distribution\n",
        "# Plotting pie chart\n",
        "\n",
        "churn_counts = df['Churn'].value_counts()\n",
        "explode = [0.05] * len(churn_counts)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.pie(churn_counts, labels=churn_counts.index, autopct='%1.1f%%', startangle=90, explode=explode, colors=['lightgreen', 'lightcoral'])\n",
        "plt.title('Churn Distribution')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5qa0HxMrD2M"
      },
      "outputs": [],
      "source": [
        "# Checking unique values in each column\n",
        "\n",
        "for col in df.columns:\n",
        "    print(f\"\\nColumn: {col}\")\n",
        "    print(\"Unique values:\", df[col].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etdaW0NUO96K"
      },
      "source": [
        "####**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEIhNLRGjmhO"
      },
      "outputs": [],
      "source": [
        "# Dropping CustomerID and standardizing categorical values\n",
        "\n",
        "df_clean = df.drop(columns=['CustomerID'])\n",
        "df_clean['PreferredLoginDevice'] = df_clean['PreferredLoginDevice'].replace({'Phone': 'Mobile Phone'})\n",
        "df_clean['PreferredPaymentMode'] = df_clean['PreferredPaymentMode'].replace({'CC': 'Credit Card', 'COD': 'Cash on Delivery'})\n",
        "df_clean['PreferedOrderCat'] = df_clean['PreferedOrderCat'].replace({'Mobile': 'Mobile Phone'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mpje6urOqGfU"
      },
      "outputs": [],
      "source": [
        "df_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJO5xeOErrSH"
      },
      "outputs": [],
      "source": [
        "#Feature Engineering\n",
        "#Creates new features: AvgOrderValue, RecentComplaint\n",
        "\n",
        "df_clean['AvgOrderValue'] = df_clean['CashbackAmount'] / df_clean['OrderCount'].replace(0, 1)\n",
        "df_clean['RecentComplaint'] = (df_clean['Complain'] == 1).astype(int)\n",
        "df_clean[['AvgOrderValue', 'RecentComplaint']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqAqi2KVPflE"
      },
      "outputs": [],
      "source": [
        "# Removing duplicate rows\n",
        "\n",
        "print(f\"Number of duplicate rows: {df_clean.duplicated().sum()}\")\n",
        "df_clean = df_clean.drop_duplicates()\n",
        "print(f\"Number of duplicate rows after removal: {df_clean.duplicated().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wbagHF_QPCU"
      },
      "outputs": [],
      "source": [
        "# Handling Missing Values\n",
        "# Imputes missing values (IterativeImputer for numerical, median for HourSpendOnApp)\n",
        "\n",
        "missing_cols = df_clean.columns[df_clean.isnull().mean() > 0]\n",
        "print(f\"Columns with missing values: {missing_cols}\")\n",
        "if len(missing_cols) > 0:\n",
        "    iter_cols = [col for col in missing_cols if col != 'HourSpendOnApp' and col in df_clean.select_dtypes(include=['int64', 'float64']).columns]\n",
        "    if iter_cols:\n",
        "        iter_imputer = IterativeImputer(random_state=42)\n",
        "        df_clean[iter_cols] = iter_imputer.fit_transform(df_clean[iter_cols])\n",
        "    if 'HourSpendOnApp' in missing_cols:\n",
        "        simple_imputer = SimpleImputer(strategy='median')\n",
        "        df_clean['HourSpendOnApp'] = simple_imputer.fit_transform(df_clean[['HourSpendOnApp']])\n",
        "print(f\"\\nRemaining missing values: {df_clean.isnull().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing values were found in 8 columns. Numerical columns were filled using Iterative Imputer and HourSpendOnApp was filled with the median. After this step, all missing values were successfully handled."
      ],
      "metadata": {
        "id": "mkMcrNWfz_9Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl1Gr5ZfQ8Yt"
      },
      "source": [
        "####**Churn Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkZ3pje6TdQj"
      },
      "outputs": [],
      "source": [
        "# Preparing Data\n",
        "# Splits features and target, encodes categoricals, splits train/test\n",
        "\n",
        "X = df_clean.drop(columns=['Churn'])\n",
        "y = df_clean['Churn']\n",
        "X = pd.get_dummies(X, columns=X.select_dtypes(include=['object']).columns, drop_first=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A23PI07FU8YG"
      },
      "outputs": [],
      "source": [
        "# Training Logistic Regression, Decision Tree, XGBoost, SVM\n",
        "# Initializing models\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "models = {'Logistic Regression': lr, 'Decision Tree': dt, 'XGBoost': xgb, 'SVM': svm}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNHZPux6Vdwe"
      },
      "outputs": [],
      "source": [
        "# Dictionary to store precision scores\n",
        "precision_scores = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjkdhDJZVh9V"
      },
      "outputs": [],
      "source": [
        "# Training and evaluating each model\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    precision_scores[name] = precision\n",
        "    print(f\"\\n{name} Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(f\"{name} Precision (Churners): {precision:.2f}\")\n",
        "    print(f\"{name} Recall (Churners): {recall_score(y_test, y_pred):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All four models were trained and evaluated based on their ability to detect churners (class 1).\n",
        "\n",
        "Here is how they performed:\n",
        "\n",
        "*  **XGBoost** performed the best with 92% precision and 89% recall for churners, making it the most reliable model.\n",
        "*  **Decision Tree** also performed well, with 81% precision and 91% recall.\n",
        "*  **Logistic Regression** gave decent results but had lower recall (58%), meaning it missed many churners.\n",
        "*  **SVM** failed to detect any churners, with 0% precision and recall, making it unsuitable for this task.\n",
        "\n",
        "**Conclusion:** XGBoost is the most effective model for identifying churners in this dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZUpiAP8D05bl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMhTFr3aVuTT"
      },
      "outputs": [],
      "source": [
        "# Selecting best model based on precision\n",
        "\n",
        "best_model_name = max(precision_scores, key=precision_scores.get)\n",
        "best_precision = precision_scores[best_model_name]\n",
        "print(f\"\\nBest Model: {best_model_name} with Precision: {best_precision:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOCN4L5oWBQC"
      },
      "outputs": [],
      "source": [
        "# Optimizing XGBoost with Grid Search\n",
        "\n",
        "param_grid = {'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'n_estimators': [100, 200]}\n",
        "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "grid_search = GridSearchCV(xgb, param_grid, cv=5, scoring='f1')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best XGBoost Parameters:\", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX8MEmuLWUSX"
      },
      "outputs": [],
      "source": [
        "# Cross-Validation for Best Model\n",
        "# Validates best XGBoost model\n",
        "\n",
        "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='f1')\n",
        "print(f\"XGBoost Mean F1 Score (CV): {cv_scores.mean():.2f} ± {cv_scores.std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimized XGBoost model was validated using 5-fold cross-validation.\n",
        "\n",
        "It achieved a mean F1 score of 0.91 ± 0.02, indicating consistently high performance with low variance across different data splits."
      ],
      "metadata": {
        "id": "W_0qdN6c2a70"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMUt3085WywM"
      },
      "outputs": [],
      "source": [
        "# Evaluating Best Model\n",
        "# Evaluates best XGBoost model\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(f\"XGBoost Precision (Churners): {precision_score(y_test, y_pred):.2f}\")\n",
        "print(f\"XGBoost Recall (Churners): {recall_score(y_test, y_pred):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_3GZa45Txp-"
      },
      "outputs": [],
      "source": [
        "# Visualising Confusion Matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Not Churned', 'Churned'],\n",
        "            yticklabels=['Not Churned', 'Churned'])\n",
        "\n",
        "plt.title('Confusion Matrix for Churn Prediction')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aaUEwdGXPj_"
      },
      "outputs": [],
      "source": [
        "# ROI Calculation\n",
        "# Calculates ROI ($500 saved per retained customer, $100 intervention cost, just an example)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "true_positives = cm[1, 1]\n",
        "false_positives = cm[0, 1]\n",
        "roi = (true_positives * 500 - (true_positives + false_positives) * 100) / ((true_positives + false_positives) * 100 + 1)\n",
        "print(f\"XGBoost ROI: {roi:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The estimated ROI is 351.47%, meaning every 100 dollars spent could return over 350 dollars in value, making the model highly cost-effective for targeted retention efforts."
      ],
      "metadata": {
        "id": "6NdtQUb73rzO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eqq066OGXc2P"
      },
      "outputs": [],
      "source": [
        "# SHAP Feature Importance\n",
        "# Visualizes feature importance for XGBoost\n",
        "\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "plt.figure()\n",
        "shap.summary_plot(shap_values, X_test, show=False)\n",
        "plt.title('SHAP Feature Importance for XGBoost')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " It highlights the most impactful features influencing XGBoost’s churn predictions:\n",
        "\n",
        "*  **Tenure**, **Complain** and **NumberOfAddress** had the highest impact.\n",
        "*  Features like **CashbackAmount**, **SatisfactionScore** and **AvgOrderValue** also significantly influenced predictions.\n",
        "\n",
        "The color shows feature value (red = high, blue = low) and position indicates how much it pushes the prediction toward churn or not churn."
      ],
      "metadata": {
        "id": "oq_8pVgZ4bSP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n5PXNI-aWq_"
      },
      "source": [
        "####**Customer Segmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahfk4obFa1V4"
      },
      "outputs": [],
      "source": [
        "# Preparing RFM Data\n",
        "# Extracts Recency, Frequency, Monetary\n",
        "\n",
        "df_rfm = df_clean[['DaySinceLastOrder', 'OrderCount', 'CashbackAmount']].copy()\n",
        "df_rfm.columns = ['Recency', 'Frequency', 'Monetary']\n",
        "df_rfm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBCgeaMXbk9x"
      },
      "outputs": [],
      "source": [
        "# K-Means Clustering\n",
        "# Scaling data and evaluating K-Means\n",
        "\n",
        "scaler = StandardScaler()\n",
        "rfm_scaled = scaler.fit_transform(df_rfm)\n",
        "\n",
        "k_range = range(2, 9)\n",
        "kmeans_scores = []\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    labels = kmeans.fit_predict(rfm_scaled)\n",
        "    score = silhouette_score(rfm_scaled, labels)\n",
        "    kmeans_scores.append(score)\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(range(2, 9), kmeans_scores, marker='o')\n",
        "plt.title('K-Means Silhouette Scores')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.show()\n",
        "\n",
        "best_k = k_range[kmeans_scores.index(max(kmeans_scores))]\n",
        "print(f\"Best number of clusters based on silhouette score: {best_k}\")\n",
        "\n",
        "final_kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
        "df_rfm['KMeans_Cluster'] = final_kmeans.fit_predict(rfm_scaled)\n",
        "df_rfm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWaUrsgbeP9p"
      },
      "outputs": [],
      "source": [
        "# Gaussian Mixture Model (GMM) Clustering\n",
        "# Evaluating GMM\n",
        "\n",
        "gmm_scores = []\n",
        "k_range = range(2, 9)\n",
        "\n",
        "for k in k_range:\n",
        "    gmm = GaussianMixture(n_components=k, random_state=42)\n",
        "    labels = gmm.fit_predict(rfm_scaled)\n",
        "    score = silhouette_score(rfm_scaled, labels)\n",
        "    gmm_scores.append(score)\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(range(2, 9), gmm_scores, marker='o')\n",
        "plt.title('GMM Silhouette Scores')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.show()\n",
        "\n",
        "best_k = k_range[gmm_scores.index(max(gmm_scores))]\n",
        "print(f\"Best number of clusters for GMM: {best_k}\")\n",
        "\n",
        "final_gmm = GaussianMixture(n_components=best_k, random_state=42)\n",
        "df_rfm['GMM_Cluster'] = final_gmm.fit_predict(rfm_scaled)\n",
        "df_rfm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tlthTRKg0xh"
      },
      "outputs": [],
      "source": [
        "# Visualizing Clusters\n",
        "# Ploting 3D scatter plots\n",
        "\n",
        "fig = px.scatter_3d(df_rfm, x='Recency', y='Frequency', z='Monetary', color='KMeans_Cluster', title='K-Means Clusters')\n",
        "fig.show()\n",
        "fig = px.scatter_3d(df_rfm, x='Recency', y='Frequency', z='Monetary', color='GMM_Cluster', title='GMM Clusters')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbkdmwGpzilY"
      },
      "outputs": [],
      "source": [
        "# Evaluating Clusters\n",
        "\n",
        "kMeans_score = silhouette_score(rfm_scaled, df_rfm['KMeans_Cluster'])\n",
        "print(f\"RFM Silhouette Score: {kMeans_score:.3f}\")\n",
        "\n",
        "gmm_score = silhouette_score(rfm_scaled, df_rfm['GMM_Cluster'])\n",
        "print(f\"RFM Silhouette Score: {gmm_score:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lgbUMPWzi0b"
      },
      "outputs": [],
      "source": [
        "df_rfm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWHHsnZWzi4e"
      },
      "outputs": [],
      "source": [
        "# Labelling Segments Based on Cluster Means\n",
        "\n",
        "cluster_means = df_rfm.groupby('KMeans_Cluster')[['Recency', 'Frequency', 'Monetary']].mean()\n",
        "best_cluster = cluster_means['Monetary'].idxmax()\n",
        "df_rfm['Segment_Label'] = df_rfm['KMeans_Cluster'].apply(lambda x: 'High Value' if x == best_cluster else 'Low Value')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customers were segmented using K-Means clustering based on Recency, Frequency and Monetary (RFM) values.\n",
        "\n",
        "* The cluster with the highest Monetary value was labeled as “**High Value**”.\n",
        "* All other clusters were labeled as “**Low Value**”.\n"
      ],
      "metadata": {
        "id": "GeHzIayU6sIR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caW2sA2NaGEP"
      },
      "outputs": [],
      "source": [
        "df_rfm['Segment_Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeU2ZvcvzjFa"
      },
      "outputs": [],
      "source": [
        "# Visualizing Segment Distribution\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Segment_Label', data=df_rfm)\n",
        "plt.title('Customer Segment Distribution (High Value vs Low Value)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpzOmKKyzjAS"
      },
      "outputs": [],
      "source": [
        "# Defining RFM Subgroup Labels (within clusters, for analysis only)\n",
        "\n",
        "def subgroup_label(row):\n",
        "    if row['Recency'] <= df_rfm['Recency'].quantile(0.25) and \\\n",
        "       row['Frequency'] >= df_rfm['Frequency'].quantile(0.75) and \\\n",
        "       row['Monetary'] >= df_rfm['Monetary'].quantile(0.75):\n",
        "        return 'Champion'\n",
        "    elif row['Frequency'] >= df_rfm['Frequency'].quantile(0.75):\n",
        "        return 'Loyal'\n",
        "    elif row['Monetary'] >= df_rfm['Monetary'].quantile(0.75):\n",
        "        return 'Big Spender'\n",
        "    elif row['Recency'] >= df_rfm['Recency'].quantile(0.75):\n",
        "        return 'At Risk'\n",
        "    elif row['Recency'] <= df_rfm['Recency'].quantile(0.25):\n",
        "        return 'New'\n",
        "    else:\n",
        "        return 'Mid-Value'\n",
        "\n",
        "df_rfm['RFM_Subgroup'] = df_rfm.apply(subgroup_label, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within the clusters, customers were further labeled based on RFM quantiles to better understand their behavior:\n",
        "\n",
        "*  **Champion:** Recent, frequent and high spenders\n",
        "*  **Loyal:** Very frequent buyers\n",
        "*  **Big Spender:** High monetary value\n",
        "*  **At Risk:** Haven’t purchased in a while\n",
        "*  **New:** Very recent customers\n",
        "*  **Mid-Value:** Average behavior on all metrics\n",
        "\n",
        "This adds deeper insight for tailored marketing and retention strategies."
      ],
      "metadata": {
        "id": "IaC-RwPp6CVz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY9NY_8tzjCu"
      },
      "outputs": [],
      "source": [
        "df_rfm['RFM_Subgroup'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI14y_ttzjHy"
      },
      "outputs": [],
      "source": [
        "# Visualizing RFM_Subgroup Distribution\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "order = df_rfm['RFM_Subgroup'].value_counts().index\n",
        "sns.countplot(x='RFM_Subgroup', data=df_rfm, order=order)\n",
        "plt.title('RFM Subgroup Distribution')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAYxBiV0zi7H"
      },
      "outputs": [],
      "source": [
        "# Adding Churn Probability from Model\n",
        "\n",
        "df_rfm['Churn_Probability'] = best_model.predict_proba(X)[:, 1]\n",
        "df_rfm['Churn_Probability']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2C3QB5MZI1_"
      },
      "outputs": [],
      "source": [
        "# Visualizing Churn by Segment\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x='Segment_Label', y='Churn_Probability', data=df_rfm)\n",
        "plt.title('Churn Probability by Segment')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Low Value** customers show higher churn risk.\n",
        "\n",
        "**High Value** customers have lower, more stable churn probability, making them worth prioritizing for retention."
      ],
      "metadata": {
        "id": "JZaGO3Yg8F0v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfX1GdnvZJEf"
      },
      "outputs": [],
      "source": [
        "# Visualizing Churn Distribution by Segment\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for label in df_rfm['Segment_Label'].unique():\n",
        "    subset = df_rfm[df_rfm['Segment_Label'] == label]\n",
        "    sns.kdeplot(subset['Churn_Probability'], label=label, fill=True, alpha=0.3)\n",
        "\n",
        "plt.title('Churn Probability Distribution by Segment')\n",
        "plt.xlabel('Churn Probability')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpBSJJjCjf2g"
      },
      "outputs": [],
      "source": [
        "# Visualizing Churn by RFM_Subgroup\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='RFM_Subgroup', y='Churn_Probability', data=df_rfm)\n",
        "\n",
        "plt.title('Churn Probability by RFM Subgroup (Boxplot)')\n",
        "plt.ylabel('Churn Probability')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New customers show the highest churn risk.\n",
        "\n",
        "Champions and Loyal customers have the lowest churn probability, making them key groups to retain and nurture."
      ],
      "metadata": {
        "id": "ymAPrJvb8ldo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8xl_4XMd9oK"
      },
      "outputs": [],
      "source": [
        "# Visualizing Churn by RFM_Subgroup\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.stripplot(x='RFM_Subgroup', y='Churn_Probability', data=df_rfm, jitter=True, alpha=0.6)\n",
        "plt.title('Churn Probability by RFM_Subgroup')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn6SQmt3ayu7"
      },
      "outputs": [],
      "source": [
        "# Identifying High-Risk Customers by Segment\n",
        "\n",
        "high_risk = df_rfm[df_rfm['Churn_Probability'] > 0.7]\n",
        "high_risk[['Segment_Label', 'Churn_Probability']].groupby('Segment_Label').size().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1Y5XmvngpT-"
      },
      "outputs": [],
      "source": [
        "# Identifying High-Risk Customers by RFM_Subgroup\n",
        "\n",
        "high_risk = df_rfm[df_rfm['Churn_Probability'] > 0.7]\n",
        "high_risk[['RFM_Subgroup', 'Churn_Probability']].groupby('RFM_Subgroup').size().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNcw1NfSg6Pw"
      },
      "outputs": [],
      "source": [
        "# Visualizing High-Risk Customers\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Normal churn points (gray)\n",
        "sns.stripplot(\n",
        "    x='RFM_Subgroup',\n",
        "    y='Churn_Probability',\n",
        "    data=df_rfm[df_rfm['Churn_Probability'] <= 0.7],\n",
        "    jitter=True,\n",
        "    alpha=0.5,\n",
        "    color='gray'\n",
        ")\n",
        "\n",
        "# High-risk churn points (red)\n",
        "sns.stripplot(\n",
        "    x='RFM_Subgroup',\n",
        "    y='Churn_Probability',\n",
        "    data=df_rfm[df_rfm['Churn_Probability'] > 0.7],\n",
        "    jitter=True,\n",
        "    alpha=0.8,\n",
        "    color='red'\n",
        ")\n",
        "\n",
        "plt.title('High-Risk Customers (Red = Churn > 0.7)')\n",
        "plt.ylabel('Churn Probability')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfPiQAbrqiFX"
      },
      "outputs": [],
      "source": [
        "# Visualizing High-Risk Customers\n",
        "\n",
        "high_risk = df_rfm[df_rfm['Churn_Probability'] > 0.7]\n",
        "high_risk_counts = high_risk['RFM_Subgroup'].value_counts().sort_values(ascending=False)\n",
        "\n",
        "colors = sns.color_palette(\"Reds_r\", len(high_risk_counts))\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=high_risk_counts.index, y=high_risk_counts.values, palette=colors)\n",
        "plt.title('High-Risk Customers (Churn > 0.7)')\n",
        "plt.xlabel('RFM Subgroup')\n",
        "plt.ylabel('No. of High-Risk Customers')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most high-risk churners (churn probability > 0.7) are from the **New**, **Loyal** and **Mid-Value** subgroups.\n",
        "\n",
        "Targeted engagement strategies for these segments can help reduce churn and protect revenue."
      ],
      "metadata": {
        "id": "FFe2fpxO846t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEIRRRbsV9iC"
      },
      "outputs": [],
      "source": [
        "# Adding CustomerID from df to df_rfm using index\n",
        "\n",
        "df_rfm['CustomerID'] = df.loc[df_clean.index, 'CustomerID'].values\n",
        "\n",
        "# Adding columns from df_clean to df_rfm using index alignment\n",
        "\n",
        "columns_to_add = ['SatisfactionScore', 'PreferredPaymentMode', 'PreferedOrderCat']\n",
        "df_rfm[columns_to_add] = df_clean[columns_to_add]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvBywzr7ayxq"
      },
      "outputs": [],
      "source": [
        "# Segment Summary Report\n",
        "\n",
        "segment_summary = df_rfm.groupby('Segment_Label').agg({\n",
        "    'Recency': 'mean',\n",
        "    'Frequency': 'mean',\n",
        "    'Monetary': 'mean',\n",
        "    'Churn_Probability': 'mean',\n",
        "    'SatisfactionScore': 'mean',\n",
        "    'PreferredPaymentMode': lambda x: x.mode()[0],\n",
        "    'PreferedOrderCat': lambda x: x.mode()[0]\n",
        "}).round(2)\n",
        "\n",
        "segment_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**High Value** customers shop more often, spend more and have lower churn (12%)\n",
        "\n",
        "**Low Value** customers are less engaged and show higher churn risk (18%)\n",
        "\n",
        "Both segments prefer Debit Card payments, but product preferences differ:\n",
        "\n",
        "*  High Value → Laptops & Accessories\n",
        "*  Low Value → Mobile Phones\n",
        "\n"
      ],
      "metadata": {
        "id": "LXO1WLCJ9Ky6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLQa-AFdgqCq"
      },
      "outputs": [],
      "source": [
        "# RFM_Subgroup Summary Report\n",
        "\n",
        "RFM_subgroup_summary = df_rfm.groupby('RFM_Subgroup').agg({\n",
        "    'Recency': 'mean',\n",
        "    'Frequency': 'mean',\n",
        "    'Monetary': 'mean',\n",
        "    'Churn_Probability': 'mean',\n",
        "    'SatisfactionScore': 'mean',\n",
        "    'PreferredPaymentMode': lambda x: x.mode()[0],\n",
        "    'PreferedOrderCat': lambda x: x.mode()[0]\n",
        "}).round(2)\n",
        "\n",
        "RFM_subgroup_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Champion** have the highest satisfaction (3.4), low churn (7%) and high spend.\n",
        "\n",
        "**New** customers show the highest churn risk (27%) and lowest spend/satisfaction.\n",
        "\n",
        "**Big Spender** spend the most but buy less frequently.\n",
        "\n",
        "**Loyal** customers buy often but have a moderate churn risk (14%).\n",
        "\n",
        "Most subgroups prefer Debit Card, with product preferences varying across segments."
      ],
      "metadata": {
        "id": "v6vJ8u1298py"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OFAp17OZ6lU"
      },
      "source": [
        "####**Targeted Treatment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROpshnP3v4-e"
      },
      "outputs": [],
      "source": [
        "# Generating placeholder survival data\n",
        "\n",
        "survival_data = pd.DataFrame({\n",
        "    'CustomerID': df_rfm['CustomerID'].sample(49, random_state=42).values,\n",
        "    'Exp_Loss': np.random.uniform(100, 2000, 49),\n",
        "    'Uplift_Grocery': np.random.uniform(0, 500, 49),\n",
        "    'Uplift_CreditCard': np.random.uniform(0, 1000, 49),\n",
        "    'Uplift_DebitCard': np.random.uniform(0, 1000, 49)\n",
        "})\n",
        "survival_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dummy data simulation shows how much money we might lose if a customer leaves **(Exp_Loss)** and how much we could gain by offering deals through Grocery, Credit Card or Debit Card **(Uplift)**. It helps test which offers work best to keep customers."
      ],
      "metadata": {
        "id": "mc4FZyVG-yz8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eky3FFhXv5Vs"
      },
      "outputs": [],
      "source": [
        "# Merging survival data with df_rfm\n",
        "\n",
        "treatment_df = pd.merge(survival_data, df_rfm, on='CustomerID', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCIiMNTKZ_5c"
      },
      "outputs": [],
      "source": [
        "# Summarizing Treated Segment\n",
        "\n",
        "treatment_segment_label = treatment_df.groupby('Segment_Label').agg({\n",
        "    'Exp_Loss': 'sum',\n",
        "    'Uplift_Grocery': 'sum',\n",
        "    'Uplift_CreditCard': 'sum',\n",
        "    'Uplift_DebitCard': 'sum',\n",
        "    'Recency': 'mean',\n",
        "    'Frequency': 'mean',\n",
        "    'Monetary': 'mean'\n",
        "}).round(2)\n",
        "treatment_segment_label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Low Value** customers have a higher total expected loss and potential uplift across all offer types.\n",
        "\n",
        "**High Value** customers have fewer losses but higher spend and engagement (higher frequency & monetary)."
      ],
      "metadata": {
        "id": "sF4jxA0p_R3C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ygeb1LMJWaq4"
      },
      "outputs": [],
      "source": [
        "# Summarizing Treated RFM_Subgroup\n",
        "\n",
        "treatment_RFM_subgroup = treatment_df.groupby('RFM_Subgroup').agg({\n",
        "    'Exp_Loss': 'sum',\n",
        "    'Uplift_Grocery': 'sum',\n",
        "    'Uplift_CreditCard': 'sum',\n",
        "    'Uplift_DebitCard': 'sum',\n",
        "    'Recency': 'mean',\n",
        "    'Frequency': 'mean',\n",
        "    'Monetary': 'mean'\n",
        "}).round(2)\n",
        "treatment_RFM_subgroup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**New** and **Mid-Value** customers have the highest expected loss and uplift, making them key targets for retention offers.\n",
        "\n",
        "**Big Spenders** and **Loyal** customers show good uplift with higher monetary value.\n",
        "\n",
        "**At Risk** customers have lower frequency but still offer meaningful gains."
      ],
      "metadata": {
        "id": "oxI88hLM_f0L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNys1WxS9waj"
      },
      "source": [
        "####**Analysis Completed**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}